{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# for videos load \ndef load_videos(video_dir, frame_size=(64, 64), max_frames=60):\n    video_data = []\n    labels = []\n    \n    for label_dir in os.listdir(video_dir):\n        label_path = os.path.join(video_dir, label_dir)\n        if os.path.isdir(label_path):\n            label = label_dir\n            for video_file in os.listdir(label_path):\n                video_path = os.path.join(label_path, video_file)\n                cap = cv2.VideoCapture(video_path)\n                frames = []\n                \n                while len(frames) < max_frames:\n                    ret, frame = cap.read()\n                    if not ret:\n                        break\n                    frame = cv2.resize(frame, frame_size)\n                    frames.append(frame)\n                \n                cap.release()\n                \n                while len(frames) < max_frames:\n                    frames.append(np.zeros((frame_size[0], frame_size[1], 3), dtype=np.uint8))\n                \n                video_data.append(np.array(frames))\n                labels.append(label)\n\n    return np.array(video_data), np.array(labels)\n\nvideo_dir = '../input/spin-ball'  \nX, y = load_videos(video_dir)\n\n# Preprocess labels\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\nX = X / 255.0\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\n#the 3D CNN model\nmodel = models.Sequential()\n\nmodel.add(layers.Conv3D(32, (3, 3, 3), activation='relu', input_shape=(60, 64, 64, 3)))\nmodel.add(layers.MaxPooling3D((2, 2, 2)))\n\nmodel.add(layers.Conv3D(64, (3, 3, 3), activation='relu'))\nmodel.add(layers.MaxPooling3D((2, 2, 2)))\n\nmodel.add(layers.Conv3D(128, (3, 3, 3), activation='relu'))\nmodel.add(layers.MaxPooling3D((2, 2, 2)))\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dropout(0.5))  # Dropout for regularization\n\nmodel.add(layers.Dense(len(label_encoder.classes_), activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Print model summary\nmodel.summary()\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n\ntest_loss, test_acc = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {test_acc}\")\n\n# classification Report\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\nprint(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n\n# Save the model\nmodel.save('video_classification_3dcnn_model.h5')\n\n# Function to classify new videos\ndef classify_video(video_path, model, label_encoder, frame_size=(64, 64), max_frames=60):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    \n    while len(frames) < max_frames:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame = cv2.resize(frame, frame_size)\n        frames.append(frame)\n    \n    cap.release()\n    \n    while len(frames) < max_frames:\n        frames.append(np.zeros((frame_size[0], frame_size[1], 3), dtype=np.uint8))\n    \n    frames = np.array(frames) / 255.0\n    frames = np.expand_dims(frames, axis=0)  # Add batch dimension\n    \n    predictions = model.predict(frames)\n    predicted_class = np.argmax(predictions, axis=1)\n    \n    return label_encoder.inverse_transform(predicted_class)[0]\n\n# Example usage\nvideo_path = 'path_to_new_video.mp4' \npredicted_label = classify_video(video_path, model, label_encoder)\nprint(f'Predicted label: {predicted_label}')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-10T00:22:23.444976Z","iopub.execute_input":"2024-09-10T00:22:23.445366Z","iopub.status.idle":"2024-09-10T00:22:40.653229Z","shell.execute_reply.started":"2024-09-10T00:22:23.445331Z","shell.execute_reply":"2024-09-10T00:22:40.651580Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Load and preprocess the video dataset\u001b[39;00m\n\u001b[1;32m     42\u001b[0m video_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input/spin-ball\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Update this to your dataset path\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Preprocess labels\u001b[39;00m\n\u001b[1;32m     46\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n","Cell \u001b[0;32mIn[1], line 15\u001b[0m, in \u001b[0;36mload_videos\u001b[0;34m(video_dir, frame_size, max_frames)\u001b[0m\n\u001b[1;32m     12\u001b[0m video_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label_dir \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     16\u001b[0m     label_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(video_dir, label_dir)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(label_path):\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/spin-ball'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/spin-ball'","output_type":"error"}]}]}